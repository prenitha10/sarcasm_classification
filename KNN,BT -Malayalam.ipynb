{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1v1m3Ube8jJ01pkRMClHIwfeE5Mvv0ghR","authorship_tag":"ABX9TyMM93mCHgK8lL1ysKfS46Zo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"G7NstTcZfsIP","executionInfo":{"status":"ok","timestamp":1725638268478,"user_tz":-330,"elapsed":378,"user":{"displayName":"JANE","userId":"04368026904399864163"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g3WyGGqEDIim","executionInfo":{"status":"ok","timestamp":1725706983010,"user_tz":-330,"elapsed":120178,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"d85c550a-3dda-48f8-9caf-62ff901e7d7d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Load datasets\n","mal_train = pd.read_csv('/content/drive/MyDrive/sarcasm_mal_train.csv')\n","mal_test = pd.read_csv('/content/drive/MyDrive/sarcasm_mal_test_without_labels.csv')\n","mal_val = pd.read_csv('/content/drive/MyDrive/sarcasm_mal_dev.csv')\n"],"metadata":{"id":"4uALXm4df4w_","executionInfo":{"status":"ok","timestamp":1725638273499,"user_tz":-330,"elapsed":1153,"user":{"displayName":"JANE","userId":"04368026904399864163"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["pip install indic-transliteration"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"c50zqJe9f6eO","executionInfo":{"status":"ok","timestamp":1725638278897,"user_tz":-330,"elapsed":5403,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"a31e9df0-2808-4855-ceb8-3733212ac368"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting indic-transliteration\n","  Downloading indic_transliteration-2.3.61-py3-none-any.whl.metadata (1.4 kB)\n","Collecting backports.functools-lru-cache (from indic-transliteration)\n","  Downloading backports.functools_lru_cache-2.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (2024.5.15)\n","Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (0.12.5)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (0.10.2)\n","Collecting roman (from indic-transliteration)\n","  Downloading roman-4.2-py3-none-any.whl.metadata (3.6 kB)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer->indic-transliteration) (8.1.7)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from typer->indic-transliteration) (4.12.2)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer->indic-transliteration) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer->indic-transliteration) (13.8.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer->indic-transliteration) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer->indic-transliteration) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer->indic-transliteration) (0.1.2)\n","Downloading indic_transliteration-2.3.61-py3-none-any.whl (153 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/153.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading backports.functools_lru_cache-2.0.0-py2.py3-none-any.whl (6.7 kB)\n","Downloading roman-4.2-py3-none-any.whl (5.5 kB)\n","Installing collected packages: roman, backports.functools-lru-cache, indic-transliteration\n","Successfully installed backports.functools-lru-cache-2.0.0 indic-transliteration-2.3.61 roman-4.2\n"]}]},{"cell_type":"code","source":["pip install --upgrade indic-nlp-library"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"zUG2tQ4wgE1r","executionInfo":{"status":"ok","timestamp":1725638296199,"user_tz":-330,"elapsed":17307,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"c456f813-df55-4799-88d3-00b87a7b7bf6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting indic-nlp-library\n","  Downloading indic_nlp_library-0.92-py3-none-any.whl.metadata (5.7 kB)\n","Collecting sphinx-argparse (from indic-nlp-library)\n","  Downloading sphinx_argparse-0.5.2-py3-none-any.whl.metadata (3.7 kB)\n","Collecting sphinx-rtd-theme (from indic-nlp-library)\n","  Downloading sphinx_rtd_theme-2.0.0-py2.py3-none-any.whl.metadata (4.4 kB)\n","Collecting morfessor (from indic-nlp-library)\n","  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (2.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2024.1)\n","Collecting sphinx>=5.1.0 (from sphinx-argparse->indic-nlp-library)\n","  Downloading sphinx-8.0.2-py3-none-any.whl.metadata (6.2 kB)\n","Collecting docutils>=0.19 (from sphinx-argparse->indic-nlp-library)\n","  Downloading docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\n","Collecting sphinx>=5.1.0 (from sphinx-argparse->indic-nlp-library)\n","  Downloading sphinx-7.4.7-py3-none-any.whl.metadata (6.1 kB)\n","Collecting docutils>=0.19 (from sphinx-argparse->indic-nlp-library)\n","  Downloading docutils-0.20.1-py3-none-any.whl.metadata (2.8 kB)\n","Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->indic-nlp-library)\n","  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.16.0)\n","Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n","Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n","Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n","Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.0)\n","Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n","Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n","Requirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.4)\n","Collecting Pygments>=2.17 (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library)\n","  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n","Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.16.0)\n","Requirement already satisfied: alabaster~=0.7.14 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (0.7.16)\n","Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n","Requirement already satisfied: requests>=2.30.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.32.3)\n","Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (24.1)\n","Requirement already satisfied: tomli>=2 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2024.8.30)\n","Downloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n","Downloading sphinx_argparse-0.5.2-py3-none-any.whl (12 kB)\n","Downloading sphinx_rtd_theme-2.0.0-py2.py3-none-any.whl (2.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading docutils-0.20.1-py3-none-any.whl (572 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.7/572.7 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sphinx-7.4.7-py3-none-any.whl (3.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: morfessor, Pygments, docutils, sphinx, sphinxcontrib-jquery, sphinx-argparse, sphinx-rtd-theme, indic-nlp-library\n","  Attempting uninstall: Pygments\n","    Found existing installation: Pygments 2.16.1\n","    Uninstalling Pygments-2.16.1:\n","      Successfully uninstalled Pygments-2.16.1\n","  Attempting uninstall: docutils\n","    Found existing installation: docutils 0.18.1\n","    Uninstalling docutils-0.18.1:\n","      Successfully uninstalled docutils-0.18.1\n","  Attempting uninstall: sphinx\n","    Found existing installation: Sphinx 5.0.2\n","    Uninstalling Sphinx-5.0.2:\n","      Successfully uninstalled Sphinx-5.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed Pygments-2.18.0 docutils-0.20.1 indic-nlp-library-0.92 morfessor-2.0.6 sphinx-7.4.7 sphinx-argparse-0.5.2 sphinx-rtd-theme-2.0.0 sphinxcontrib-jquery-4.1\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from indic_transliteration import sanscript\n","from indic_transliteration.sanscript import transliterate\n","\n","def reverse_transliterate_text(text):\n","    return transliterate(text, sanscript.ITRANS, sanscript.MALAYALAM)\n","\n","# Apply reverse transliteration to each DataFrame\n","mal_train['Text'] = mal_train['Text'].apply(reverse_transliterate_text)\n","mal_val['Text'] = mal_val['Text'].apply(reverse_transliterate_text)\n","mal_test['Text'] = mal_test['Text'].apply(reverse_transliterate_text)\n"],"metadata":{"id":"-qO9g_sPgIOR","executionInfo":{"status":"ok","timestamp":1725638302825,"user_tz":-330,"elapsed":6631,"user":{"displayName":"JANE","userId":"04368026904399864163"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import re\n","\n","def remove_emojis(text):\n","    # Regular expression pattern to match emojis\n","    emoji_pattern = re.compile(\n","        \"[\"                        # Match any character in the following ranges\n","        \"\\U0001F600-\\U0001F64F\"    # Emoticons\n","        \"\\U0001F300-\\U0001F5FF\"    # Miscellaneous Symbols and Pictographs\n","        \"\\U0001F680-\\U0001F6FF\"    # Transport and Map Symbols\n","        \"\\U0001F700-\\U0001F77F\"    # Alchemical Symbols\n","        \"\\U0001F780-\\U0001F7FF\"    # Geometric Shapes Extended\n","        \"\\U0001F800-\\U0001F8FF\"    # Supplemental Arrows-C\n","        \"\\U0001F900-\\U0001F9FF\"    # Supplemental Symbols and Pictographs\n","        \"\\U0001FA00-\\U0001FA6F\"    # Chess Symbols\n","        \"\\U0001FA70-\\U0001FAFF\"    # Symbols and Pictographs Extended-A\n","        \"\\U00002702-\\U000027B0\"    # Dingbats\n","        \"\\U000024C2-\\U0001F251\"    # Enclosed Alphanumeric Supplement\n","        \"]+\", flags=re.UNICODE)    # Include Unicode flag for proper handling\n","\n","    return emoji_pattern.sub(r'', text)\n"],"metadata":{"id":"uvGM9auqgM9W","executionInfo":{"status":"ok","timestamp":1725638302826,"user_tz":-330,"elapsed":8,"user":{"displayName":"JANE","userId":"04368026904399864163"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["mal_train['Text'] = mal_train['Text'].apply(remove_emojis)\n","mal_val['Text'] = mal_train['Text'].apply(remove_emojis)\n","mal_test['Text'] = mal_test['Text'].apply(remove_emojis)"],"metadata":{"id":"_QszqkufgQJt","executionInfo":{"status":"ok","timestamp":1725638302827,"user_tz":-330,"elapsed":7,"user":{"displayName":"JANE","userId":"04368026904399864163"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["import re\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from indicnlp.tokenize import indic_tokenize"],"metadata":{"id":"Vn1GD6OlgZax","executionInfo":{"status":"ok","timestamp":1725638306280,"user_tz":-330,"elapsed":3459,"user":{"displayName":"JANE","userId":"04368026904399864163"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["malayalam_stopwords = set([\n","    'അത്', 'എന്റെ', 'ഇത്', 'ഒരു', 'എനിക്ക്', 'ആകും', 'ഇല്ല', 'ഞാൻ', 'താൻ', 'ഉണ്ടാണ്', 'ആക', 'അവിടെ', 'വരിക',\n","    'അവിടെ', 'കൂടാതെ', 'അദ്ദേഹം', 'അവൾ', 'അതിനാൽ', 'അങ്ങനെ', 'മറ്റു', 'ഒരുപാടു', 'ആണെങ്കിൽ', 'അവർ', 'അവർക്ക്',\n","    'അവർക്ക്', 'ഇങ്ങനെയാണ്', 'അതുകൂടാതെ', 'എന്തുകൊണ്ടു', 'ഇവിടെ', 'അടുത്ത', 'അവരെ', 'പിന്നീട്', 'അവളുടെ',\n","    'ആകുന്നു', 'അതുകൂടാതെ', 'എന്താണെന്ന്', 'അവ', 'അവരുടെ', 'ഇവ', 'കഴിഞ്ഞ', 'പിന്നീട്', 'പോലുള്ള', 'എന്തെങ്കിലും',\n","    'അങ്ങനെയാണ്', 'അതേസമയം', 'അവർക്കു', 'സഹായം', 'തന്നെ', 'വേഗം', 'അവർ', 'നിന്നു', 'അവരെ', 'നിങ്ങളുടെ', 'അവർ',\n","    'പോലുള്ള', 'ഇപ്പോഴേക്കും', 'ആവശ്യമായ', 'പിറകേ', 'സഹായം', 'അവരെ', 'അവരുടെ', 'അതിനു', 'അല്ല', 'പോലുള്ള',\n","    'പെരുമാൾ', 'ഇങ്ങനെ', 'ഉണ്ട്', 'അല്ലാത്ത', 'എങ്കിൽ', 'അങ്ങനെയോ', 'പിന്നീട്', 'ഉണ്ടായിരിക്കണം', 'ഉടൻ', 'അത്',\n","    'മോഡൽ', 'ഇത്ര', 'ആകുന്നു', 'ആകുന്നത്', 'അവിടെ', 'ഇതിനുപരി', 'കൂടുതൽ', 'അക്ക', 'ചെയ്യുന്നു', 'വഴിയുണ്ട്',\n","    'മറ്റുള്ളവർ', 'ആയിരിക്കും', 'മുമ്പ്', 'ആകും', 'എല്ലാ', 'എന്നാലും', 'എന്തായാലും', 'എന്തായിരിക്കും', 'അതുകൊണ്ടു',\n","    'ഒരുപാട്', 'അവിടുത്തെ', 'അവിടെ', 'ഇനിയും', 'പിന്നീട്', 'പിന്നീട്', 'ഒടുവിൽ', 'ഇത്', 'അവർക്കു', 'ആവശ്യം'\n","])\n"],"metadata":{"id":"Syz311o3gbt6","executionInfo":{"status":"ok","timestamp":1725638306281,"user_tz":-330,"elapsed":5,"user":{"displayName":"JANE","userId":"04368026904399864163"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["pip install nltk\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uxNzotiVge8A","executionInfo":{"status":"ok","timestamp":1725638313754,"user_tz":-330,"elapsed":7478,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"6f1e9935-d852-4a1d-8374-fcf4bf5bf375"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"]}]},{"cell_type":"code","source":["import re\n","import nltk\n","import pandas as pd\n","\n","# Download the necessary NLTK data (if not already downloaded)\n","nltk.download('punkt')\n","\n","def preprocess_text(text):\n","    # Ensure the text is a string\n","    if not isinstance(text, str):\n","        return ''\n","\n","    # Lowercase the text\n","    text = text.lower()\n","\n","    # Keep Malayalam letters and spaces; remove everything else\n","    text = re.sub(r'[^\\u0D00-\\u0D7F\\s]', ' ', text)\n","\n","    # Remove extra spaces\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","\n","    # Tokenize text using NLTK\n","    tokens = nltk.word_tokenize(text)\n","\n","\n","    # Remove stopwords\n","    tokens = [word for word in tokens if word not in malayalam_stopwords]\n","\n","    # Join tokens back into a single string\n","    return ' '.join(tokens)\n","\n","# Apply preprocessing to the DataFrames\n","mal_train['Text'] = mal_train['Text'].apply(preprocess_text)\n","mal_val['Text'] = mal_val['Text'].apply(preprocess_text)\n","mal_test['Text'] = mal_test['Text'].apply(preprocess_text)\n","\n","# Print DataFrames to verify\n","print(\"Training DataFrame:\")\n","print(mal_train)\n","print(\"\\nValidation DataFrame:\")\n","print(mal_val)\n","print(\"\\nTest DataFrame:\")\n","print(mal_test)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tdDFKgpbghD_","executionInfo":{"status":"ok","timestamp":1725638318477,"user_tz":-330,"elapsed":4729,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"0f2a3d8e-8991-49dc-e9b7-e823cd54aee9"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Training DataFrame:\n","                                                    Text         labels\n","0          ഷ്ച്രീന്ശോത് ഏദുക്കന് വന്ന്ഥ് ന്ജന് മാത്രമാണോ      Sarcastic\n","1      നമ്മുടെ അനു സിത്താര ചേച്ചി വരുന്നത് നോക്കി ഇരു...      Sarcastic\n","2      ംഓല്ല്യ്ഹൂദ് ഇസ് ഗേത്തിന്ഗ് ബിഗ്ഗേര് അന്ദ് ബിഗ...  Non-sarcastic\n","3         ഃഓ ആഅ ്ം ംഅമ്മൂക്ക ഇഥു ഓരു പ്വോലി പ്വോലിക്കുമ്  Non-sarcastic\n","4      ന്ഥാലേ സമ്ഭവമ് പുരാനമ് ആനേലുമ് ബച്ക്ഗ്രോഉന്ദ് ...      Sarcastic\n","...                                                  ...            ...\n","13183         ംഅധു ഛ് ണരയനന് പ്രതീക്ഷ ഉള്ള സംവിധയകൻ കൂടി  Non-sarcastic\n","13184  ക്യ മ ക് ഹൈ ഃഅന്സ് ഹന്സ് ക് ലോത്പോത് ഹോ ജഓഗേ ഛ...  Non-sarcastic\n","13185  ചന്നേല് ആഅനു ഇശ്തപേത്തല് സുബ്സ്ച്രിബേ ചേയ്യുമോ...  Non-sarcastic\n","13186                   ണ്തേ പോന്നോ കിദിലമ് മരന വൈതിന്ഗ്  Non-sarcastic\n","13187  ഈക്കയുദേ ജോഹ്ന്യ് വല്കേര് ഓര്മ്മ വരുന്നൂ വേരേ ...  Non-sarcastic\n","\n","[13188 rows x 2 columns]\n","\n","Validation DataFrame:\n","                                                   Text         labels\n","0         ഷ്ച്രീന്ശോത് ഏദുക്കന് വന്ന്ഥ് ന്ജന് മാത്രമാണോ  Non-sarcastic\n","1     നമ്മുടെ അനു സിത്താര ചേച്ചി വരുന്നത് നോക്കി ഇരു...  Non-sarcastic\n","2     ംഓല്ല്യ്ഹൂദ് ഇസ് ഗേത്തിന്ഗ് ബിഗ്ഗേര് അന്ദ് ബിഗ...  Non-sarcastic\n","3        ഃഓ ആഅ ്ം ംഅമ്മൂക്ക ഇഥു ഓരു പ്വോലി പ്വോലിക്കുമ്      Sarcastic\n","4     ന്ഥാലേ സമ്ഭവമ് പുരാനമ് ആനേലുമ് ബച്ക്ഗ്രോഉന്ദ് ...      Sarcastic\n","...                                                 ...            ...\n","2821  ഇതിന്റെ സെക്കന്റ് പാർട്ട് എടുക്കണം എന്ന് ഉള്ളവ...  Non-sarcastic\n","2822  മാമാങ്കതിനോടൊപ്പം വൈത് ചെയ്യാൻ ഇതേമ് കൂടി മൂത്...  Non-sarcastic\n","2823             സുരാജ് ലൂക്സ് ലികേ ഓഉര് കുന്ജുന്നി മശ്  Non-sarcastic\n","2824  ത്ത വൈതിന്ഗ് ബിഗ് ബ്രോഥേര് ലല്ലേതാ ലല്ലേതന് ന്...  Non-sarcastic\n","2825                          ംഅരന വൈതിന്ഗ് മസ്സ്സ്സ്സ്  Non-sarcastic\n","\n","[2826 rows x 2 columns]\n","\n","Test DataFrame:\n","           ID                                               Text\n","0       Id_01  ഷവകല്ലരയിലേ ുഴിമാദഥിലേ ഏരില് രു ളേത്തേര് മരച് ...\n","1       Id_02  ഗീതു മോഹൻദാസ് മലയാള സിനിമക്കു നൽകുന്ന വമ്പൻ ഗി...\n","2       Id_03                  ന്തേ പോന്നോ അഹ് സോഉന്ദ് പോലി പോലി\n","3       Id_04      ഇല്ലൈന് ശര ുധീന് ഏന്നു ഥോന്നുന്നവര് ലികിക്കൂഊ\n","4       Id_05                    പുലിമുരുകന് ത്രൈലേര് അനോ കനുനഥ്\n","...       ...                                                ...\n","2821  Id_2822  ന്തേ പോന്നോ ഓരു അദാരു ജഗപോക ആനേനു മനസിലായി ില്...\n","2822  Id_2823              ഇക്ക ന്ജ നമിച്ചു രക്ഷയില്ല ഹെവി ഐറ്റം\n","2823  Id_2824  ദേ ഇപ്പൊ കണ്ട് ഇറങ്ങിയതേ ഉള്ളു ൯൬ രിക്കു ൨ പിന...\n","2824  Id_2825  ൧ ഡ്രിസ്യമ് ൨ ംഏമോരിഏസ് ൩ ഷേചോന്ദ്സ് ൪ ്രന്ദ് ...\n","2825  Id_2826            ഷുപേര് മമ്മൂഓക്ക്കാഅ രു ലലേത്തന് ഭക്ഥന്\n","\n","[2826 rows x 2 columns]\n"]}]},{"cell_type":"code","source":["\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# For simplicity, concatenate train and validation data\n","data = pd.concat([mal_train, mal_val], ignore_index=True)\n","\n","# Vectorize the text using TF-IDF\n","vectorizer = TfidfVectorizer(max_features=5000)\n","X = vectorizer.fit_transform(data['Text'])\n","y = data['labels']  # Assuming 'Label' column exists for target labels\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Train a K-Nearest Neighbors model\n","knn_model = KNeighborsClassifier(n_neighbors=5)\n","knn_model.fit(X_train, y_train)\n","\n","# Predict on the test set using KNN\n","knn_y_pred = knn_model.predict(X_test)\n","\n","# Evaluate the KNN model\n","print(\"KNN Model Accuracy:\", accuracy_score(y_test, knn_y_pred))\n","print(\"KNN Classification Report:\\n\", classification_report(y_test, knn_y_pred))\n","\n","# Predict on tam_test data using KNN\n","mal_test_vectorized = vectorizer.transform(mal_test['Text'])\n","mal_test_knn_predictions = knn_model.predict(mal_test_vectorized)\n","\n","# Print KNN predictions for tam_test data\n","print(\"KNN Predictions for tam_test:\\n\", pd.Series(mal_test_knn_predictions).value_counts())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"evpfqJjBgjRG","executionInfo":{"status":"ok","timestamp":1725638345953,"user_tz":-330,"elapsed":27484,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"101e9b84-7fc7-4343-ec59-eb3da17b8dec"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["KNN Model Accuracy: 0.8054948485794567\n","KNN Classification Report:\n","                precision    recall  f1-score   support\n","\n","Non-sarcastic       0.81      0.99      0.89      2581\n","    Sarcastic       0.49      0.05      0.09       622\n","\n","     accuracy                           0.81      3203\n","    macro avg       0.65      0.52      0.49      3203\n"," weighted avg       0.75      0.81      0.73      3203\n","\n","KNN Predictions for tam_test:\n"," Non-sarcastic    2791\n","Sarcastic          35\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"mZ-uPGiChmw3","executionInfo":{"status":"ok","timestamp":1725638345954,"user_tz":-330,"elapsed":12,"user":{"displayName":"JANE","userId":"04368026904399864163"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["KNN_mal_test_predictions_series = pd.Series(mal_test_knn_predictions)\n","\n","# Get value counts\n","value_counts = KNN_mal_test_predictions_series.value_counts()\n","\n","# Print value counts\n","print(\"Value counts of predictions:\\n\", value_counts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yeywTPzxhLqq","executionInfo":{"status":"ok","timestamp":1725638345954,"user_tz":-330,"elapsed":11,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"e5e37200-a3cf-4374-8146-ba7ff21a73d7"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Value counts of predictions:\n"," Non-sarcastic    2791\n","Sarcastic          35\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":["results = pd.DataFrame({\n","    'ID': mal_test['ID'],\n","    'Label': KNN_mal_test_predictions_series\n","})\n","\n","# Print the results\n","print(results)\n","\n","# Optionally, save the results to a CSV file\n","results.to_csv('KNN*mal*test*predictions.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iAET--ashcUv","executionInfo":{"status":"ok","timestamp":1725638345954,"user_tz":-330,"elapsed":8,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"14a1dcb6-ff5c-4d90-ba85-415037142eea"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["           ID          Label\n","0       Id_01  Non-sarcastic\n","1       Id_02  Non-sarcastic\n","2       Id_03  Non-sarcastic\n","3       Id_04  Non-sarcastic\n","4       Id_05  Non-sarcastic\n","...       ...            ...\n","2821  Id_2822  Non-sarcastic\n","2822  Id_2823  Non-sarcastic\n","2823  Id_2824  Non-sarcastic\n","2824  Id_2825  Non-sarcastic\n","2825  Id_2826  Non-sarcastic\n","\n","[2826 rows x 2 columns]\n"]}]},{"cell_type":"code","source":["\n","# Decision Tree Model\n","dt_model = DecisionTreeClassifier()\n","dt_model.fit(X_train, y_train)\n","dt_y_pred = dt_model.predict(X_test)\n","\n","print(\"Decision Tree Model Accuracy:\", accuracy_score(y_test, dt_y_pred))\n","print(\"Decision Tree Classification Report:\\n\", classification_report(y_test, dt_y_pred))\n","\n","# Predict on tam_test data using the best performing model (for demonstration, using both models)\n","mal_test_vectorized = vectorizer.transform(mal_test['Text'])\n","\n","# Predictions using Decision Tree\n","dt_mal_test_predictions = dt_model.predict(mal_test_vectorized)\n","print(\"Decision Tree Predictions for tam_test data:\\n\", dt_mal_test_predictions)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PVnyqx8BhzjA","executionInfo":{"status":"ok","timestamp":1725638355107,"user_tz":-330,"elapsed":9158,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"54065f77-a8fc-444e-e7aa-7ef1bc26839c"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Decision Tree Model Accuracy: 0.7489853262566344\n","Decision Tree Classification Report:\n","                precision    recall  f1-score   support\n","\n","Non-sarcastic       0.83      0.87      0.85      2581\n","    Sarcastic       0.31      0.25      0.28       622\n","\n","     accuracy                           0.75      3203\n","    macro avg       0.57      0.56      0.56      3203\n"," weighted avg       0.73      0.75      0.74      3203\n","\n","Decision Tree Predictions for tam_test data:\n"," ['Non-sarcastic' 'Non-sarcastic' 'Non-sarcastic' ... 'Sarcastic'\n"," 'Non-sarcastic' 'Non-sarcastic']\n"]}]},{"cell_type":"code","source":["result3 = pd.DataFrame({\n","    'ID': mal_test['ID'],\n","    'Label': dt_mal_test_predictions\n","})\n","\n","# Print the results\n","print(result3)\n","\n","# Optionally, save the results to a CSV file\n","result3.to_csv('DT*mal*test*predictions.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YaWil8yFiazS","executionInfo":{"status":"ok","timestamp":1725638355107,"user_tz":-330,"elapsed":17,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"864757f4-976d-4f0d-8bd6-3e86d16c2b75"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["           ID          Label\n","0       Id_01  Non-sarcastic\n","1       Id_02  Non-sarcastic\n","2       Id_03  Non-sarcastic\n","3       Id_04  Non-sarcastic\n","4       Id_05  Non-sarcastic\n","...       ...            ...\n","2821  Id_2822  Non-sarcastic\n","2822  Id_2823  Non-sarcastic\n","2823  Id_2824      Sarcastic\n","2824  Id_2825  Non-sarcastic\n","2825  Id_2826  Non-sarcastic\n","\n","[2826 rows x 2 columns]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"rSh8Xq2Tihp0","executionInfo":{"status":"ok","timestamp":1725638355107,"user_tz":-330,"elapsed":15,"user":{"displayName":"JANE","userId":"04368026904399864163"}}},"execution_count":19,"outputs":[]}]}