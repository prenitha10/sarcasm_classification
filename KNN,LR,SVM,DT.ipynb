{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"A9gZNMftgO8K"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","tam_train=pd.read_csv(\"/content/drive/MyDrive/CodalabSarcasmData/sarcasm_tam_train.csv\")\n","tam_val=pd.read_csv(\"/content/drive/MyDrive/CodalabSarcasmData/sarcasm_tam_dev.csv\")\n","tam_test=pd.read_csv(\"/content/drive/MyDrive/CodalabSarcasmData/sarcasm_tam_test_without_labels.csv\")"]},{"cell_type":"markdown","metadata":{"id":"s4etgHQ5g2H0"},"source":["Labels-alpha to numeric\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"id":"HQyn257_gmdZ","executionInfo":{"status":"ok","timestamp":1724482300089,"user_tz":-330,"elapsed":19,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"ba90e262-86b2-4a9e-ff60-698c3accc0d8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["labels\n","Non-sarcastic    21740\n","Sarcastic         7830\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>labels</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Non-sarcastic</th>\n","      <td>21740</td>\n","    </tr>\n","    <tr>\n","      <th>Sarcastic</th>\n","      <td>7830</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":3}],"source":["tam_train[\"labels\"].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MIKREr0kg72D","colab":{"base_uri":"https://localhost:8080/","height":178},"executionInfo":{"status":"ok","timestamp":1724482300089,"user_tz":-330,"elapsed":16,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"e5266083-2838-429f-9583-e598c2beb588"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["labels\n","Non-sarcastic    4630\n","Sarcastic        1706\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>labels</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Non-sarcastic</th>\n","      <td>4630</td>\n","    </tr>\n","    <tr>\n","      <th>Sarcastic</th>\n","      <td>1706</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":4}],"source":["tam_val[\"labels\"].value_counts()"]},{"cell_type":"code","source":["tam_val.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"x2vL_bujGis_","executionInfo":{"status":"ok","timestamp":1724482300089,"user_tz":-330,"elapsed":14,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"78be57ec-4174-46ef-91f3-7dae55221732"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                Text         labels\n","0  Trailer bangam youv shankar yepaya ni ippadi o...      Sarcastic\n","1  Good  morning  Thala fans.... Trailer semma ya...  Non-sarcastic\n","2            Chiyan vikram fans  Hit like bgm likers  Non-sarcastic\n","3              Chei ivala oru azhu punda ollal punda  Non-sarcastic\n","4  எவன் எதை சொன்னாலும் யோசிக்காதீர், அருமையா இருக...  Non-sarcastic"],"text/html":["\n","  <div id=\"df-78b4d1af-7e2f-4b8b-a05d-7d7175c3e98a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Trailer bangam youv shankar yepaya ni ippadi o...</td>\n","      <td>Sarcastic</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Good  morning  Thala fans.... Trailer semma ya...</td>\n","      <td>Non-sarcastic</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Chiyan vikram fans  Hit like bgm likers</td>\n","      <td>Non-sarcastic</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Chei ivala oru azhu punda ollal punda</td>\n","      <td>Non-sarcastic</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>எவன் எதை சொன்னாலும் யோசிக்காதீர், அருமையா இருக...</td>\n","      <td>Non-sarcastic</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78b4d1af-7e2f-4b8b-a05d-7d7175c3e98a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-78b4d1af-7e2f-4b8b-a05d-7d7175c3e98a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-78b4d1af-7e2f-4b8b-a05d-7d7175c3e98a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-1509e9e9-cc62-4492-a606-d833c15b71ca\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1509e9e9-cc62-4492-a606-d833c15b71ca')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-1509e9e9-cc62-4492-a606-d833c15b71ca button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"tam_val","summary":"{\n  \"name\": \"tam_val\",\n  \"rows\": 6336,\n  \"fields\": [\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6319,\n        \"samples\": [\n          \"\\u0b87\\u0ba4\\u0bc1 1996 \\u0baf\\u0bbe\\u0bb0 \\u0b8f\\u0bae\\u0bbe\\u0ba4\\u0bcd\\u0ba4 \\u0baa\\u0bbe\\u0b95\\u0bcd\\u0b95\\u0bbf\\u0bb1\\u0bc0\\u0b99\\u0bcd\\u0b95?\",\n          \"marninng elunthu undan thala tharishanam thaan\",\n          \"To 14k unlikers orutharmela viswasam kaatrathuku eathuku inoruthara asinga paduthuringa\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Non-sarcastic\",\n          \"Sarcastic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["Convert the lettern in english to tam\n"],"metadata":{"id":"lpjwO_tkGzRE"}},{"cell_type":"code","source":["pip install indic-transliteration"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w_yJzgRZG31t","executionInfo":{"status":"ok","timestamp":1724482304853,"user_tz":-330,"elapsed":4776,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"d2d8bf9b-3529-4dc1-d85e-c52067306931"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting indic-transliteration\n","  Downloading indic_transliteration-2.3.61-py3-none-any.whl.metadata (1.4 kB)\n","Collecting backports.functools-lru-cache (from indic-transliteration)\n","  Downloading backports.functools_lru_cache-2.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (2024.5.15)\n","Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (0.12.4)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (0.10.2)\n","Collecting roman (from indic-transliteration)\n","  Downloading roman-4.2-py3-none-any.whl.metadata (3.6 kB)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer->indic-transliteration) (8.1.7)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from typer->indic-transliteration) (4.12.2)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer->indic-transliteration) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer->indic-transliteration) (13.7.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer->indic-transliteration) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer->indic-transliteration) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer->indic-transliteration) (0.1.2)\n","Downloading indic_transliteration-2.3.61-py3-none-any.whl (153 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/153.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading backports.functools_lru_cache-2.0.0-py2.py3-none-any.whl (6.7 kB)\n","Downloading roman-4.2-py3-none-any.whl (5.5 kB)\n","Installing collected packages: roman, backports.functools-lru-cache, indic-transliteration\n","Successfully installed backports.functools-lru-cache-2.0.0 indic-transliteration-2.3.61 roman-4.2\n"]}]},{"cell_type":"code","source":["from indic_transliteration import sanscript\n","from indic_transliteration.sanscript import transliterate\n","\n","# Assuming tam_train, tam_val, and tam_test are predefined DataFrames with a 'Text' column\n","def reverse_transliterate_text(text):\n","    return transliterate(text, sanscript.ITRANS, sanscript.TAMIL)\n","\n","tam_train['Text'] = tam_train['Text'].apply(reverse_transliterate_text)\n","tam_val['Text'] = tam_val['Text'].apply(reverse_transliterate_text)\n","tam_test['Text'] = tam_test['Text'].apply(reverse_transliterate_text)"],"metadata":{"id":"0SrvqiKPG4JW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tam_train.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"bTjC9j9OG8Ea","executionInfo":{"status":"ok","timestamp":1724482328372,"user_tz":-330,"elapsed":11,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"16811940-8d4a-41c1-def2-bb083d794622"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                Text         labels\n","0  அர்யவுக்கு  ஒரு நல்ல வாய்ப்பு சிங்கம் சூரியா அ...  Non-sarcastic\n","1  பள்ளியோ கல்லூரியோ படித்துக்கொண்டிருக்கும்போது ...  Non-sarcastic\n","2  தல தல தல தல தல தல தல தல தல தல தல தல தல தல தல த...  Non-sarcastic\n","3  ஆல்ல் தே பேஸ்த் தோ தே தேஅம்॥॥ஸுபேர் அஹ் ந Oரு ...  Non-sarcastic\n","4  Bஅஹுத் ஓவேர் மச்க் உப் கிய ஹுஅ ஹை, இத் இஸ் லூக...  Non-sarcastic"],"text/html":["\n","  <div id=\"df-7d62ab34-9a13-4cc5-ae7c-a184f12063a1\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>அர்யவுக்கு  ஒரு நல்ல வாய்ப்பு சிங்கம் சூரியா அ...</td>\n","      <td>Non-sarcastic</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>பள்ளியோ கல்லூரியோ படித்துக்கொண்டிருக்கும்போது ...</td>\n","      <td>Non-sarcastic</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>தல தல தல தல தல தல தல தல தல தல தல தல தல தல தல த...</td>\n","      <td>Non-sarcastic</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ஆல்ல் தே பேஸ்த் தோ தே தேஅம்॥॥ஸுபேர் அஹ் ந Oரு ...</td>\n","      <td>Non-sarcastic</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Bஅஹுத் ஓவேர் மச்க் உப் கிய ஹுஅ ஹை, இத் இஸ் லூக...</td>\n","      <td>Non-sarcastic</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d62ab34-9a13-4cc5-ae7c-a184f12063a1')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7d62ab34-9a13-4cc5-ae7c-a184f12063a1 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7d62ab34-9a13-4cc5-ae7c-a184f12063a1');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-44e083ed-1bd2-4ac7-b26f-48b4ca7e2b13\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-44e083ed-1bd2-4ac7-b26f-48b4ca7e2b13')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-44e083ed-1bd2-4ac7-b26f-48b4ca7e2b13 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"tam_train","summary":"{\n  \"name\": \"tam_train\",\n  \"rows\": 29570,\n  \"fields\": [\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29362,\n        \"samples\": [\n          \"\\u0b95\\u0bcb\\u0bae\\u0bcd\\u0bae \\u0baa\\u0bc1\\u0ba8\\u0bcd\\u0ba4 \\u0bae\\u0bb0\\u0bbf \\u0b87\\u0bb0\\u0bbf\\u0b95\\u0bc2\\u0b8a\\u0b89 \\u0ba4\\u0bc7\\u0bb5\\u0bbf\\u0ba4\\u0bbf\\u0baf\\u0bbe\\u0b86 \\u0b85\\u0b9c\\u0bbf\\u0ba4\\u0bcd \\u0b83\\u0baa\\u0ba8\\u0bcd\\u0bb8\\u0bcd\",\n          \"\\u0b9f\\u0bb2\\u0bc8\\u0bb5\\u0bbf \\u0ba8\\u0bb9\\u0bbf\\u0965 \\u0baa\\u0bb0\\u0bcd \\u0b9a\\u0bbf\\u0ba8\\u0bb2\\u0bcd \\u0bb2\\u0b95\\u0bcd \\u0bb0\\u0bcd\\u0bb9\\u0bbf \\u0bb9\\u0bc7\\u0965\",\n          \"\\u0b85\\u0baa\\u0bcd\\u0baa\\u0b9f\\u0bbf \\u0ba4\\u0bbe\\u0ba9\\u0bcd \\u0b95\\u0bb2\\u0bcd\\u0baf\\u0bbe\\u0ba3\\u0bae\\u0bcd \\u0b9a\\u0bc6\\u0baf\\u0bcd\\u0bb5\\u0bcb\\u0bae\\u0bcd \\u0b85\\u0ba4\\u0bc1\\u0b95\\u0bcd\\u0b95\\u0bc1 \\u0b8e\\u0ba9\\u0bcd\\u0ba9 \\u0b87\\u0baa\\u0bcd\\u0baa\\u0bcb\\u0965\\u0965\\u0964 \\u0b87\\u0bb0\\u0ba3\\u0bcd\\u0b9f\\u0bc1 \\u0baa\\u0bc7\\u0bb0\\u0bcd \\u0b95\\u0bbe\\u0ba4\\u0bb2\\u0bc1\\u0bae\\u0bcd \\u0b89\\u0ba3\\u0bcd\\u0bae\\u0bc8\\u0baf\\u0bbe \\u0b87\\u0bb0\\u0bc1\\u0ba8\\u0bcd\\u0ba4\\u0bbe \\u0b9a\\u0bbe\\u0ba4\\u0bbf\\u0baf\\u0bc6\\u0bb2\\u0bcd\\u0bb2\\u0bbe\\u0bae\\u0bcd \\u0baa\\u0bbe\\u0bb0\\u0bcd\\u0b95\\u0bcd\\u0b95 \\u0bae\\u0bc1\\u0b9f\\u0bbf\\u0baf\\u0bbe\\u0ba4\\u0bc1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Sarcastic\",\n          \"Non-sarcastic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["indic library"],"metadata":{"id":"R14U8zHfHCxW"}},{"cell_type":"code","source":["pip install --upgrade indic-nlp-libraryu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JyzyM0TrG8Wl","executionInfo":{"status":"ok","timestamp":1724482369300,"user_tz":-330,"elapsed":40935,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"71da3963-5f27-4236-e5cc-2b04f2e49d5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting indic-nlp-library\n","  Downloading indic_nlp_library-0.92-py3-none-any.whl.metadata (5.7 kB)\n","Collecting sphinx-argparse (from indic-nlp-library)\n","  Downloading sphinx_argparse-0.5.2-py3-none-any.whl.metadata (3.7 kB)\n","Collecting sphinx-rtd-theme (from indic-nlp-library)\n","  Downloading sphinx_rtd_theme-2.0.0-py2.py3-none-any.whl.metadata (4.4 kB)\n","Collecting morfessor (from indic-nlp-library)\n","  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (2.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2024.1)\n","Collecting sphinx>=5.1.0 (from sphinx-argparse->indic-nlp-library)\n","  Downloading sphinx-8.0.2-py3-none-any.whl.metadata (6.2 kB)\n","Collecting docutils>=0.19 (from sphinx-argparse->indic-nlp-library)\n","  Downloading docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\n","Collecting sphinx>=5.1.0 (from sphinx-argparse->indic-nlp-library)\n","  Downloading sphinx-7.4.7-py3-none-any.whl.metadata (6.1 kB)\n","Collecting docutils>=0.19 (from sphinx-argparse->indic-nlp-library)\n","  Downloading docutils-0.20.1-py3-none-any.whl.metadata (2.8 kB)\n","Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->indic-nlp-library)\n","  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.16.0)\n","Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n","Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n","Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n","Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.0)\n","Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n","Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n","Requirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.4)\n","Collecting Pygments>=2.17 (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library)\n","  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n","Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.16.0)\n","Requirement already satisfied: alabaster~=0.7.14 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (0.7.16)\n","Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n","Requirement already satisfied: requests>=2.30.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.32.3)\n","Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (24.1)\n","Requirement already satisfied: tomli>=2 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2024.7.4)\n","Downloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n","Downloading sphinx_argparse-0.5.2-py3-none-any.whl (12 kB)\n","Downloading sphinx_rtd_theme-2.0.0-py2.py3-none-any.whl (2.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading docutils-0.20.1-py3-none-any.whl (572 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.7/572.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sphinx-7.4.7-py3-none-any.whl (3.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: morfessor, Pygments, docutils, sphinx, sphinxcontrib-jquery, sphinx-argparse, sphinx-rtd-theme, indic-nlp-library\n","  Attempting uninstall: Pygments\n","    Found existing installation: Pygments 2.16.1\n","    Uninstalling Pygments-2.16.1:\n","      Successfully uninstalled Pygments-2.16.1\n","  Attempting uninstall: docutils\n","    Found existing installation: docutils 0.18.1\n","    Uninstalling docutils-0.18.1:\n","      Successfully uninstalled docutils-0.18.1\n","  Attempting uninstall: sphinx\n","    Found existing installation: Sphinx 5.0.2\n","    Uninstalling Sphinx-5.0.2:\n","      Successfully uninstalled Sphinx-5.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed Pygments-2.18.0 docutils-0.20.1 indic-nlp-library-0.92 morfessor-2.0.6 sphinx-7.4.7 sphinx-argparse-0.5.2 sphinx-rtd-theme-2.0.0 sphinxcontrib-jquery-4.1\n"]}]},{"cell_type":"code","source":["import re\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from indicnlp.tokenize import indic_tokenize"],"metadata":{"id":"PqkN1jv2HGP4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tamil_stopwords = set([\n","    'அது', 'என்', 'இது', 'ஒரு', 'என', 'ஆகும்', 'இல்லை', 'நான்', 'தான்', 'உள்ள', 'ஆக', 'இருக்கும்', 'அங்கு',\n","    'இருந்து', 'போது', 'அங்கு', 'உடன்', 'அழகு', 'அவன்', 'அவள்', 'எனவே', 'மற்றும்', 'விட', 'முதலாவது', 'அறிக்கை',\n","    'முக்கியம்', 'மற்றும்', 'உதவிய', 'எடுத்த', 'மற்றும்', 'அனுபவம்', 'தனி', 'மட்டும்', 'நீங்கள்', 'குறித்து', 'என்',\n","    'அவருக்கு', 'அவரது', 'என்ன', 'மதிப்பெண்கள்', 'நிறைய', 'முற்றிலும்', 'சிறந்த', 'தற்காலிக', 'முடிவு', 'துணை',\n","    'போல்', 'உங்கள்', 'ஒரே', 'கிடைக்காது', 'அந்த', 'அவை', 'அறிந்து', 'வசதி', 'மாதிரியான', 'வகையில்', 'அந்த',\n","    'இங்கு', 'அடுத்த', 'இயக்க', 'நிறுத்த', 'தற்காலிகமாக', 'அவரை', 'அவள்', 'பிறகு', 'அவையை', 'நிலையை',\n","    'நீடிக்கும்', 'நீளும்', 'அனைத்து', 'என்றால்', 'வழி', 'ஆதாரம்', 'ஆவணம்', 'முக்கிய', 'ஒரே', 'ஆண்டுதான்',\n","    'மற்ற', 'வரை', 'எப்படி', 'அவை', 'இங்கே', 'அங்கு', 'அவர்கள்', 'உண்மை', 'மிக', 'சில', 'ஏன்', 'காரணம்',\n","    'சரி', 'அப்புறம்', 'அப்போது', 'அதனால்', 'அடுத்தது', 'அதுவும்', 'அதற்குப்', 'ஆகிய', 'அவர்கள்', 'பிறர்',\n","    'அந்த', 'பின்னர்', 'பின்', 'இதுவரை', 'முதல்', 'நேற்று', 'இரவில்', 'அப்போது', 'தினமும்', 'இருந்து',\n","    'பின்னர்', 'மற்றும்', 'பிறகு', 'நேரத்தில்', 'நேரம்', 'நேரத்தில்', 'எப்பொழுதும்', 'எப்போதும்', 'எப்பொழுது',\n","    'போதும்', 'நேரமும்', 'அவையும்', 'நீங்கள்', 'அவர்கள்', 'என்பது', 'எனவே', 'வழியாக', 'ஆகிய', 'நினைவில்',\n","    'அதை', 'அதுவே', 'அதில்', 'அந்த', 'அவர்களை', 'அவர்களின்', 'அவர்கள்', 'அவர்கள்'\n","])\n"],"metadata":{"id":"bXSBx0wEHJ8p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess_text(text):\n","    # Lowercase the text\n","    text = text.lower()\n","    # Remove unwanted characters and keep Tamil letters and spaces\n","    text = re.sub(r'[^\\u0B80-\\u0BFF\\s]', ' ', text)\n","    # Remove extra spaces\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    # Tokenize text\n","    tokens = indic_tokenize.trivial_tokenize(text)\n","    # Remove stopwords\n","    tokens = [word for word in tokens if word not in tamil_stopwords]\n","    return ' '.join(tokens)\n","tam_train['Text'] = tam_train['Text'].apply(preprocess_text)\n","tam_val['Text'] = tam_val['Text'].apply(preprocess_text)\n","tam_test['Text'] = tam_test['Text'].apply(preprocess_text)"],"metadata":{"id":"U8OFkJSlIbxH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, accuracy_score"],"metadata":{"id":"OevaO6GfIibA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = pd.concat([tam_train, tam_val], ignore_index=True)\n","# Vectorize the text using TF-IDF\n","vectorizer = TfidfVectorizer(max_features=5000)\n","X = vectorizer.fit_transform(data['Text'])\n","y = data['labels']  # Assuming 'Label' column exists for target labels\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"JSeMwdDkIzb-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Logistic Regression"],"metadata":{"id":"ADCibkbEI6uc"}},{"cell_type":"code","source":["# Train a Logistic Regression model\n","model = LogisticRegression(max_iter=1000)\n","model.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred = model.predict(X_test)\n","\n","# Evaluate the model\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","\n","# Predict on tam_test data\n","tam_test_vectorized = vectorizer.transform(tam_test['Text'])\n","tam_test_prediction1 = model.predict(tam_test_vectorized)\n","\n","# Print predictions for tam_test data\n","print(tam_test_prediction1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WruVBZfBI221","executionInfo":{"status":"ok","timestamp":1724482376765,"user_tz":-330,"elapsed":2120,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"49977a88-eef8-442a-b532-18ca4527739d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.7592592592592593\n","Classification Report:\n","                precision    recall  f1-score   support\n","\n","Non-sarcastic       0.78      0.94      0.85      5291\n","    Sarcastic       0.60      0.26      0.36      1891\n","\n","     accuracy                           0.76      7182\n","    macro avg       0.69      0.60      0.61      7182\n"," weighted avg       0.73      0.76      0.72      7182\n","\n","['Non-sarcastic' 'Non-sarcastic' 'Non-sarcastic' ... 'Non-sarcastic'\n"," 'Non-sarcastic' 'Non-sarcastic']\n"]}]},{"cell_type":"code","source":["LR_tam_test_predictions_series = pd.Series(tam_test_prediction1)\n","\n","# Get value counts\n","value_counts = LR_tam_test_predictions_series.value_counts()\n","\n","# Print value counts\n","print(\"Value counts of predictions:\\n\", value_counts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"daNlEZEVI93f","executionInfo":{"status":"ok","timestamp":1724482465168,"user_tz":-330,"elapsed":8,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"6b2c9c1b-5e36-48e6-c845-d3ada5771437"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Value counts of predictions:\n"," Non-sarcastic    5586\n","Sarcastic         752\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":["results = pd.DataFrame({\n","    'ID': tam_test['ID'],\n","    'Label': LR_tam_test_predictions_series\n","})\n","\n","# Print the results\n","print(results)\n","\n","# Optionally, save the results to a CSV file\n","results.to_csv('LR_tam_test_predictions.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2-6Wo22rMGqt","executionInfo":{"status":"ok","timestamp":1724482569018,"user_tz":-330,"elapsed":438,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"262a18f9-6439-4484-c929-b7958f63c3eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["           ID          Label\n","0       Id_01  Non-sarcastic\n","1       Id_02  Non-sarcastic\n","2       Id_03  Non-sarcastic\n","3       Id_04  Non-sarcastic\n","4       Id_05  Non-sarcastic\n","...       ...            ...\n","6333  Id_6334  Non-sarcastic\n","6334  Id_6335      Sarcastic\n","6335  Id_6336  Non-sarcastic\n","6336  Id_6337  Non-sarcastic\n","6337  Id_6338  Non-sarcastic\n","\n","[6338 rows x 2 columns]\n"]}]},{"cell_type":"markdown","source":["SVM"],"metadata":{"id":"aZa6gr6RJO12"}},{"cell_type":"code","source":["import pandas as pd\n","import re\n","from indicnlp.tokenize import indic_tokenize\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# Define your custom stopwords set\n","tamil_stopwords = set([\n","    'அது', 'என்', 'இது', 'ஒரு', 'என', 'ஆகும்', 'இல்லை', 'நான்', 'தான்', 'உள்ள', 'ஆக', 'இருக்கும்', 'அங்கு',\n","    'இருந்து', 'போது', 'அங்கு', 'உடன்', 'அழகு', 'அவன்', 'அவள்', 'எனவே', 'மற்றும்', 'விட', 'முதலாவது', 'அறிக்கை',\n","    'முக்கியம்', 'மற்றும்', 'உதவிய', 'எடுத்த', 'மற்றும்', 'அனுபவம்', 'தனி', 'மட்டும்', 'நீங்கள்', 'குறித்து', 'என்',\n","    'அவருக்கு', 'அவரது', 'என்ன', 'மதிப்பெண்கள்', 'நிறைய', 'முற்றிலும்', 'சிறந்த', 'தற்காலிக', 'முடிவு', 'துணை',\n","    'போல்', 'உங்கள்', 'ஒரே', 'கிடைக்காது', 'அந்த', 'அவை', 'அறிந்து', 'வசதி', 'மாதிரியான', 'வகையில்', 'அந்த',\n","    'இங்கு', 'அடுத்த', 'இயக்க', 'நிறுத்த', 'தற்காலிகமாக', 'அவரை', 'அவள்', 'பிறகு', 'அவையை', 'நிலையை',\n","    'நீடிக்கும்', 'நீளும்', 'அனைத்து', 'என்றால்', 'வழி', 'ஆதாரம்', 'ஆவணம்', 'முக்கிய', 'ஒரே', 'ஆண்டுதான்'\n","])\n","\n","def preprocess_text(text):\n","    # Lowercase the text\n","    text = text.lower()\n","    # Remove unwanted characters and keep Tamil letters and spaces\n","    text = re.sub(r'[^\\u0B80-\\u0BFF\\s]', ' ', text)\n","    # Remove extra spaces\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    # Tokenize text\n","    tokens = indic_tokenize.trivial_tokenize(text)\n","    # Remove stopwords\n","    tokens = [word for word in tokens if word not in tamil_stopwords]\n","    return ' '.join(tokens)\n","\n","# Apply the preprocessing function\n","tam_train['Text'] = tam_train['Text'].apply(preprocess_text)\n","tam_val['Text'] = tam_val['Text'].apply(preprocess_text)\n","tam_test['Text'] = tam_test['Text'].apply(preprocess_text)\n","\n","# For simplicity, concatenate train and validation data\n","data = pd.concat([tam_train, tam_val], ignore_index=True)\n","\n","# Vectorize the text using TF-IDF\n","vectorizer = TfidfVectorizer(max_features=5000)\n","X = vectorizer.fit_transform(data['Text'])\n","y = data['labels']  # Assuming 'Label' column exists for target labels\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Train an SVM model\n","model = SVC(kernel='linear', max_iter=1000)\n","model.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred = model.predict(X_test)\n","\n","# Evaluate the model\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","\n","# Predict on tam_test data\n","tam_test_vectorized = vectorizer.transform(tam_test['Text'])\n","tam_test_predictions = model.predict(tam_test_vectorized)\n","\n","# Convert predictions to a pandas Series\n","SVM_tam_test_predictions_series = pd.Series(tam_test_predictions)\n","\n","# Get value counts\n","value_counts = LR_tam_test_predictions_series.value_counts()\n","\n","# Print value counts\n","print(\"Value counts of predictions:\\n\", value_counts)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qw-bjsJuJKIt","executionInfo":{"status":"ok","timestamp":1724482608272,"user_tz":-330,"elapsed":14813,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"6db5384c-9f2f-4d99-e6aa-3ddbe82120a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.6720969089390142\n","Classification Report:\n","                precision    recall  f1-score   support\n","\n","Non-sarcastic       0.76      0.81      0.78      5291\n","    Sarcastic       0.35      0.28      0.31      1891\n","\n","     accuracy                           0.67      7182\n","    macro avg       0.55      0.55      0.55      7182\n"," weighted avg       0.65      0.67      0.66      7182\n","\n","Value counts of predictions:\n"," Non-sarcastic    5586\n","Sarcastic         752\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":["result2 = pd.DataFrame({\n","    'ID': tam_test['ID'],\n","    'Label': SVM_tam_test_predictions_series\n","})\n","\n","# Print the results\n","print(result2)\n","\n","# Optionally, save the results to a CSV file\n","result2.to_csv('SVM_tam_test_predictions.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vcKU3atqJQeb","executionInfo":{"status":"ok","timestamp":1724482614019,"user_tz":-330,"elapsed":515,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"e1665881-850b-41d3-d497-d7a301f95dbf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["           ID          Label\n","0       Id_01  Non-sarcastic\n","1       Id_02  Non-sarcastic\n","2       Id_03  Non-sarcastic\n","3       Id_04      Sarcastic\n","4       Id_05  Non-sarcastic\n","...       ...            ...\n","6333  Id_6334  Non-sarcastic\n","6334  Id_6335  Non-sarcastic\n","6335  Id_6336  Non-sarcastic\n","6336  Id_6337  Non-sarcastic\n","6337  Id_6338  Non-sarcastic\n","\n","[6338 rows x 2 columns]\n"]}]},{"cell_type":"markdown","source":["KNN"],"metadata":{"id":"1xY5MpVKjDn3"}},{"cell_type":"code","source":["import pandas as pd\n","import re\n","from indicnlp.tokenize import indic_tokenize\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# Define your custom stopwords set\n","tamil_stopwords = set([\n","    'அது', 'என்', 'இது', 'ஒரு', 'என', 'ஆகும்', 'இல்லை', 'நான்', 'தான்', 'உள்ள', 'ஆக', 'இருக்கும்', 'அங்கு',\n","    'இருந்து', 'போது', 'அங்கு', 'உடன்', 'அழகு', 'அவன்', 'அவள்', 'எனவே', 'மற்றும்', 'விட', 'முதலாவது', 'அறிக்கை',\n","    'முக்கியம்', 'மற்றும்', 'உதவிய', 'எடுத்த', 'மற்றும்', 'அனுபவம்', 'தனி', 'மட்டும்', 'நீங்கள்', 'குறித்து', 'என்',\n","    'அவருக்கு', 'அவரது', 'என்ன', 'மதிப்பெண்கள்', 'நிறைய', 'முற்றிலும்', 'சிறந்த', 'தற்காலிக', 'முடிவு', 'துணை',\n","    'போல்', 'உங்கள்', 'ஒரே', 'கிடைக்காது', 'அந்த', 'அவை', 'அறிந்து', 'வசதி', 'மாதிரியான', 'வகையில்', 'அந்த',\n","    'இங்கு', 'அடுத்த', 'இயக்க', 'நிறுத்த', 'தற்காலிகமாக', 'அவரை', 'அவள்', 'பிறகு', 'அவையை', 'நிலையை',\n","    'நீடிக்கும்', 'நீளும்', 'அனைத்து', 'என்றால்', 'வழி', 'ஆதாரம்', 'ஆவணம்', 'முக்கிய', 'ஒரே', 'ஆண்டுதான்'\n","])\n","\n","def preprocess_text(text):\n","    # Lowercase the text\n","    text = text.lower()\n","    # Remove unwanted characters and keep Tamil letters and spaces\n","    text = re.sub(r'[^\\u0B80-\\u0BFF\\s]', ' ', text)\n","    # Remove extra spaces\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    # Tokenize text\n","    tokens = indic_tokenize.trivial_tokenize(text)\n","    # Remove stopwords\n","    tokens = [word for word in tokens if word not in tamil_stopwords]\n","    return ' '.join(tokens)\n","\n","# Apply the preprocessing function\n","tam_train['Text'] = tam_train['Text'].apply(preprocess_text)\n","tam_val['Text'] = tam_val['Text'].apply(preprocess_text)\n","tam_test['Text'] = tam_test['Text'].apply(preprocess_text)\n","\n","# For simplicity, concatenate train and validation data\n","data = pd.concat([tam_train, tam_val], ignore_index=True)\n","\n","# Vectorize the text using TF-IDF\n","vectorizer = TfidfVectorizer(max_features=5000)\n","X = vectorizer.fit_transform(data['Text'])\n","y = data['labels']  # Assuming 'Label' column exists for target labels\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Train a K-Nearest Neighbors model\n","knn_model = KNeighborsClassifier(n_neighbors=5)\n","knn_model.fit(X_train, y_train)\n","\n","# Predict on the test set using KNN\n","knn_y_pred = knn_model.predict(X_test)\n","\n","# Evaluate the KNN model\n","print(\"KNN Model Accuracy:\", accuracy_score(y_test, knn_y_pred))\n","print(\"KNN Classification Report:\\n\", classification_report(y_test, knn_y_pred))\n","\n","# Predict on tam_test data using KNN\n","tam_test_vectorized = vectorizer.transform(tam_test['Text'])\n","tam_test_knn_predictions = knn_model.predict(tam_test_vectorized)\n","\n","# Print KNN predictions for tam_test data\n","print(\"KNN Predictions for tam_test:\\n\", pd.Series(tam_test_knn_predictions).value_counts())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VsJeGdaEifCG","executionInfo":{"status":"ok","timestamp":1724482672919,"user_tz":-330,"elapsed":56205,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"3772a8b8-14d2-47d3-aa63-45911b0b78d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["KNN Model Accuracy: 0.74255082149819\n","KNN Classification Report:\n","                precision    recall  f1-score   support\n","\n","Non-sarcastic       0.76      0.95      0.84      5291\n","    Sarcastic       0.54      0.16      0.25      1891\n","\n","     accuracy                           0.74      7182\n","    macro avg       0.65      0.56      0.55      7182\n"," weighted avg       0.70      0.74      0.69      7182\n","\n","KNN Predictions for tam_test:\n"," Non-sarcastic    5850\n","Sarcastic         488\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":["result3 = pd.DataFrame({\n","    'ID': tam_test['ID'],\n","    'Label': tam_test_knn_predictions\n","})\n","\n","# Print the results\n","print(result3)\n","\n","# Optionally, save the results to a CSV file\n","result3.to_csv('KNN_tam_test_predictions.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SCQHlkMWjGGy","executionInfo":{"status":"ok","timestamp":1724482672919,"user_tz":-330,"elapsed":20,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"95a188b4-e1a8-498d-de97-a46be86a1446"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["           ID          Label\n","0       Id_01  Non-sarcastic\n","1       Id_02  Non-sarcastic\n","2       Id_03  Non-sarcastic\n","3       Id_04  Non-sarcastic\n","4       Id_05  Non-sarcastic\n","...       ...            ...\n","6333  Id_6334  Non-sarcastic\n","6334  Id_6335      Sarcastic\n","6335  Id_6336  Non-sarcastic\n","6336  Id_6337  Non-sarcastic\n","6337  Id_6338  Non-sarcastic\n","\n","[6338 rows x 2 columns]\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZZ1YSXgfJJFf","executionInfo":{"status":"ok","timestamp":1725706926687,"user_tz":-330,"elapsed":16563,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"3f923ede-fb05-4734-e0fd-a5274d4f1525"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["Decision Tree"],"metadata":{"id":"s6NoqPfVoWf-"}},{"cell_type":"code","source":["import pandas as pd\n","import re\n","from indicnlp.tokenize import indic_tokenize\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# Define your custom stopwords set\n","tamil_stopwords = set([\n","    'அது', 'என்', 'இது', 'ஒரு', 'என', 'ஆகும்', 'இல்லை', 'நான்', 'தான்', 'உள்ள', 'ஆக', 'இருக்கும்', 'அங்கு',\n","    'இருந்து', 'போது', 'அங்கு', 'உடன்', 'அழகு', 'அவன்', 'அவள்', 'எனவே', 'மற்றும்', 'விட', 'முதலாவது', 'அறிக்கை',\n","    'முக்கியம்', 'மற்றும்', 'உதவிய', 'எடுத்த', 'மற்றும்', 'அனுபவம்', 'தனி', 'மட்டும்', 'நீங்கள்', 'குறித்து', 'என்',\n","    'அவருக்கு', 'அவரது', 'என்ன', 'மதிப்பெண்கள்', 'நிறைய', 'முற்றிலும்', 'சிறந்த', 'தற்காலிக', 'முடிவு', 'துணை',\n","    'போல்', 'உங்கள்', 'ஒரே', 'கிடைக்காது', 'அந்த', 'அவை', 'அறிந்து', 'வசதி', 'மாதிரியான', 'வகையில்', 'அந்த',\n","    'இங்கு', 'அடுத்த', 'இயக்க', 'நிறுத்த', 'தற்காலிகமாக', 'அவரை', 'அவள்', 'பிறகு', 'அவையை', 'நிலையை',\n","    'நீடிக்கும்', 'நீளும்', 'அனைத்து', 'என்றால்', 'வழி', 'ஆதாரம்', 'ஆவணம்', 'முக்கிய', 'ஒரே', 'ஆண்டுதான்'\n","])\n","\n","def preprocess_text(text):\n","    # Lowercase the text\n","    text = text.lower()\n","    # Remove unwanted characters and keep Tamil letters and spaces\n","    text = re.sub(r'[^\\u0B80-\\u0BFF\\s]', ' ', text)\n","    # Remove extra spaces\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    # Tokenize text\n","    tokens = indic_tokenize.trivial_tokenize(text)\n","    # Remove stopwords\n","    tokens = [word for word in tokens if word not in tamil_stopwords]\n","    return ' '.join(tokens)\n","\n","# Apply the preprocessing function\n","tam_train['Text'] = tam_train['Text'].apply(preprocess_text)\n","tam_val['Text'] = tam_val['Text'].apply(preprocess_text)\n","tam_test['Text'] = tam_test['Text'].apply(preprocess_text)\n","\n","# For simplicity, concatenate train and validation data\n","data = pd.concat([tam_train, tam_val], ignore_index=True)\n","\n","# Vectorize the text using TF-IDF\n","vectorizer = TfidfVectorizer(max_features=5000)\n","X = vectorizer.fit_transform(data['Text'])\n","y = data['labels']  # Assuming 'Label' column exists for target labels\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Decision Tree Model\n","dt_model = DecisionTreeClassifier()\n","dt_model.fit(X_train, y_train)\n","dt_y_pred = dt_model.predict(X_test)\n","\n","print(\"Decision Tree Model Accuracy:\", accuracy_score(y_test, dt_y_pred))\n","print(\"Decision Tree Classification Report:\\n\", classification_report(y_test, dt_y_pred))\n","\n","# Predict on tam_test data using the best performing model (for demonstration, using both models)\n","tam_test_vectorized = vectorizer.transform(tam_test['Text'])\n","\n","# Predictions using Decision Tree\n","dt_tam_test_predictions = dt_model.predict(tam_test_vectorized)\n","print(\"Decision Tree Predictions for tam_test data:\\n\", dt_tam_test_predictions)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2G9lMQ3Hjjws","executionInfo":{"status":"ok","timestamp":1724483245510,"user_tz":-330,"elapsed":19447,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"94f53ae7-8732-4db3-df86-979ba78556b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Decision Tree Model Accuracy: 0.696463380673907\n","Decision Tree Classification Report:\n","                precision    recall  f1-score   support\n","\n","Non-sarcastic       0.78      0.82      0.80      5291\n","    Sarcastic       0.41      0.36      0.39      1891\n","\n","     accuracy                           0.70      7182\n","    macro avg       0.60      0.59      0.59      7182\n"," weighted avg       0.68      0.70      0.69      7182\n","\n","Decision Tree Predictions for tam_test data:\n"," ['Non-sarcastic' 'Non-sarcastic' 'Non-sarcastic' ... 'Sarcastic'\n"," 'Non-sarcastic' 'Non-sarcastic']\n"]}]},{"cell_type":"code","source":["result3 = pd.DataFrame({\n","    'ID': tam_test['ID'],\n","    'Label': dt_tam_test_predictions\n","})\n","\n","# Print the results\n","print(result3)\n","\n","# Optionally, save the results to a CSV file\n","result3.to_csv('DT_tam_test_predictions.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BxI-Lb3Comus","executionInfo":{"status":"ok","timestamp":1724483251883,"user_tz":-330,"elapsed":426,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"09456338-13f1-4252-e078-80792a7a28d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["           ID          Label\n","0       Id_01  Non-sarcastic\n","1       Id_02  Non-sarcastic\n","2       Id_03  Non-sarcastic\n","3       Id_04  Non-sarcastic\n","4       Id_05  Non-sarcastic\n","...       ...            ...\n","6333  Id_6334  Non-sarcastic\n","6334  Id_6335  Non-sarcastic\n","6335  Id_6336      Sarcastic\n","6336  Id_6337  Non-sarcastic\n","6337  Id_6338  Non-sarcastic\n","\n","[6338 rows x 2 columns]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"x6G_-K_Do52r"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1xGRs2eVwoJzfjdqjxOeT5nrVLa48nYOq","authorship_tag":"ABX9TyOKWX8GhpG7wdih3Jk3V983"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}